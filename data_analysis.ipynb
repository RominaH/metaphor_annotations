{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3af32a7-e5ae-4103-adeb-6c3ae59c2dbe",
   "metadata": {},
   "source": [
    "# MIP/Appraisal Corpus Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54b998-82d6-4fd6-b382-22a24a82c767",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8463c3-a059-4fb0-824c-8876fdb0539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8418cfd-ea27-4863-a1b7-0cda2d6c6906",
   "metadata": {},
   "source": [
    "## Reading and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255e23a-1998-4c32-b11d-da0760f2c5fc",
   "metadata": {},
   "source": [
    "### Metaphor Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6c8805-bed7-4d1a-9a28-df15a9e1a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from Jodie\n",
    "# helper function to build a list of lists containing the start and end indices\n",
    "# and the difference between these indices\n",
    "# where labels is the labels associated with a specific text\n",
    "def labels_to_list(labels):\n",
    "  annotations = []\n",
    "\n",
    "  labels = literal_eval(labels)\n",
    "\n",
    "  for label in labels:\n",
    "    tags = []\n",
    "    tags.append(int(label['start']))\n",
    "    tags.append(int(label['end']))\n",
    "\n",
    "    annotations.append(tags)\n",
    "\n",
    "  return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a269280a-94c0-401a-9b15-28f34ee9a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: filename, dtype: object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in EDITED metaphor annotation json and save it to a pandas dataframe\n",
    "file_path = 'MIP-at-2025-06-11-edit.json'\n",
    "met_df = pd.read_json(file_path)\n",
    "\n",
    "# extracting labels from the annotations column\n",
    "met_df['labels'] = met_df.apply(lambda row: row.annotations[0]['result'], axis=1)\n",
    "\n",
    "# changing file names so they match the appraisal folder names\n",
    "met_df['filename'] = met_df.apply(lambda row: re.sub(r\"^[^_]*-\", '', row.file_upload), axis=1)\n",
    "met_df['filename'] = met_df.apply(lambda row: re.sub(r\"_fixed\", '', row.filename[:-4]), axis=1)\n",
    "met_df['filename'] = met_df.apply(lambda row: re.sub(r\"_NEW\", '', row.filename), axis=1)\n",
    "\n",
    "# checking for duplicated files\n",
    "met_df.loc[met_df.duplicated(subset=['filename'])].filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c179bbdb-5c96-412a-8688-71d465104439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1045"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(met_df.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f04290f9-009a-42cb-9836-317ca6e881fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary of metaphor labels, where each key is a filename\n",
    "met_labels = {}\n",
    "for name in met_df['filename'].unique():\n",
    "    # creating a new dataframe only containing labels corresponding to one file\n",
    "    new_df = met_df[met_df['filename']==name][['filename', 'labels']].reset_index()\n",
    "    # creating a list to save the labels in \n",
    "    labels_list = []\n",
    "    for el in new_df['labels'][0]:\n",
    "        # adding labels to the label list using the helper function\n",
    "        labels_list.append(labels_to_list(str([el['value']]))[0])\n",
    "    # saving the list of labels to the dictionary \n",
    "    met_labels[name] = labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511ff63c-746b-476c-9013-264351adf1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1045"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(met_labels.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3cc43-196e-4475-b252-86f65be3b107",
   "metadata": {},
   "source": [
    "### Appraisal Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671a725e-60f3-4869-88a9-f9e561036db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(dic, col, txt):\n",
    "    '''\n",
    "    takes dic (a dictionary of dataframes), col (a string corresponding to column name), \n",
    "    and txt (a string containing the label type to extract) as input\n",
    "    returns a dictionary with the same keys as dic, where the values are lists of label lists (e.g., [[1,7],[9,15]])\n",
    "    '''\n",
    "    # creating a dictionary of labels, where each key is a filename and each value is a list of labels\n",
    "    labels_dic = {}\n",
    "    # looping through all the keys and values in the input dictionary\n",
    "    for name, df in dic.items():\n",
    "        # creating an empty list of labels labels\n",
    "        labels_list = []\n",
    "        # dropping rows with no labels \n",
    "        cleaned_df = df[df[col] != '_'][['indices', col]].dropna()\n",
    "        # if there are no labels, assigns an empty list\n",
    "        if len(cleaned_df[col]) == 0:\n",
    "            labels_dic[name]=labels_list\n",
    "        else:\n",
    "            # extracting rows that contain the input txt in the label column\n",
    "            dic_labels = cleaned_df[cleaned_df[col].str.contains(txt)][col].unique()\n",
    "            for d in dic_labels:\n",
    "                cleaned_df_v2 = cleaned_df[cleaned_df[col]==d]\n",
    "                # adding labels to the list of labels\n",
    "                new_dic = {}\n",
    "                new_dic[d] = {}\n",
    "                new_dic[d]['lowest'] = 1000000000\n",
    "                new_dic[d]['highest'] = -1\n",
    "                for r in cleaned_df_v2.indices:\n",
    "                    ind = [int(x) for x in r.split('-')]\n",
    "                    if ind[0] < new_dic[d]['lowest']:\n",
    "                        new_dic[d]['lowest'] = ind[0]\n",
    "                    if ind[1] > new_dic[d]['highest']:\n",
    "                        new_dic[d]['highest'] = ind[1]\n",
    "                labels_list.append([new_dic[d]['lowest'], new_dic[d]['highest']])\n",
    "            labels_dic[name]=labels_list\n",
    "    return labels_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4f55ed-89d6-42d3-9dde-43b0c915ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOES NOT EXIST: aboriginal_17\n"
     ]
    }
   ],
   "source": [
    "# creating a dictionary of appraisal annotation dataframes, where each key is a filename\n",
    "appraisal_dict = {}\n",
    "\n",
    "# list of file names in the metaphor annotations\n",
    "filenames = list(met_df['filename'].unique())\n",
    "\n",
    "# looping through each file name in the metaphor annotations \n",
    "for folder_id in filenames:\n",
    "    path = 'SOCC/annotated/Appraisal/Appraisal_annotations/curation/' + folder_id\n",
    "    try:\n",
    "        # loading in appraisal annotations in folders that end with '.txt'\n",
    "        filename = os.listdir(path + '.txt')[0]\n",
    "        # reading and saving the annotations to a pandas dataframe\n",
    "        df = pd.read_csv(path + '.txt/' + filename, sep = '\\t', header = None, \n",
    "                         skiprows=6, names=['no.','indices','text','attitude','label','polarity'])\n",
    "        # saving the dataframe to the appraisal dictionary \n",
    "        appraisal_dict[folder_id] = df\n",
    "    except:\n",
    "        try:\n",
    "            # loading in appraisal annotations in folders that end with '.tsv'\n",
    "            filename = os.listdir(path + '.tsv')[0]\n",
    "            # reading and saving the annotations to a pandas dataframe\n",
    "            df = pd.read_csv(path + '.tsv/' + filename, sep = '\\t', header = None, \n",
    "            skiprows=6, names=['no.','indices','text','attitude','label','polarity'])\n",
    "            # saving the dataframe to the appraisal dictionary\n",
    "            appraisal_dict[folder_id] = df\n",
    "        except:\n",
    "            # prints the name of any file for which there is no appraisal annotation\n",
    "            print('DOES NOT EXIST:', folder_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b732e1-de5d-4099-9616-a537302dafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del met_labels['aboriginal_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac2bc384-b3a5-408d-b232-4b2ab88ddb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(appraisal_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7f843-3f08-4a26-bbd4-556d468c2c92",
   "metadata": {},
   "source": [
    "## Corpus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3f6a5f-a6d4-4cc0-9ea1-3c92a0d7dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataframe based on the metaphor dataframe, with fewer columns\n",
    "df_analysis=met_df[['filename', 'data']]\n",
    "# removing file from that is not in appraisal dataframe\n",
    "df_analysis=df_analysis.loc[df_analysis.filename != 'aboriginal_17']\n",
    "# creating a column that measures the length of the text associated with each filename\n",
    "df_analysis['length'] = df_analysis.apply(lambda row: len(tokenizer(row.data['text'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0494f9-9f2d-4e45-b241-fd4d9b046dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>data</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>watch_30</td>\n",
       "      <td>{'text': 'Baloney.'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>watch_37</td>\n",
       "      <td>{'text': 'Exactly!'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>china_39</td>\n",
       "      <td>{'text': 'LOL...!'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>trump_38</td>\n",
       "      <td>{'text': 'Ha-Ha-Ha!!!'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                     data  length\n",
       "147  watch_30     {'text': 'Baloney.'}       1\n",
       "154  watch_37     {'text': 'Exactly!'}       1\n",
       "420  china_39      {'text': 'LOL...!'}       1\n",
       "676  trump_38  {'text': 'Ha-Ha-Ha!!!'}       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortest comments\n",
    "df_analysis.loc[(df_analysis.length == min(df_analysis.length))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a23bd1-c52b-42b2-aad9-bd842d9b5e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>data</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>uber_94</td>\n",
       "      <td>{'text': 'Uber drivers have filed a class acti...</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                               data  length\n",
       "847  uber_94  {'text': 'Uber drivers have filed a class acti...     793"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longest\n",
    "df_analysis.loc[(df_analysis.length == max(df_analysis.length))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6be91648-bd7f-4b47-a2e1-72a19d9f2fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1044 comments in the corpus. The comments range between 1 and 793 in number of tokens, with an average of 62.15900383141762. The total number of tokens in the corpus is 64894.\n"
     ]
    }
   ],
   "source": [
    "# statistics\n",
    "print('There are {} comments in the corpus. The comments range between {} and {} in number of tokens, with an average of {}. \\\n",
    "The total number of tokens in the corpus is {}.'.format(len(df_analysis), min(df_analysis.length), \n",
    "                                                        max(df_analysis.length), sum(df_analysis.length)/len(df_analysis), \n",
    "                                                        sum(df_analysis.length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ba2a5-290a-44c4-bc60-8acfde609ba1",
   "metadata": {},
   "source": [
    "# LIST OF FILENAMES FOR BOTH APPRAISAL AND LABEL STUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c0cc03-a8cc-443d-8e9d-6080bd2775f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'SOCC/annotated/Appraisal/Appraisal_annotations/curation/'\n",
    "len([filename.replace('.tsv','').replace('.txt','') for filename in os.listdir(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe6e547-a4b0-4f1f-a332-13384551df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_files = pd.DataFrame({'filename':met_df.apply(lambda row: row.filename.lower(), axis=1)})\n",
    "met_files['metaphor_files'] = met_files['filename']\n",
    "met_files=met_files.set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ed85bfe-019f-457a-8170-bd9c6fa1baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_files = pd.DataFrame({'filename':[filename.replace('.tsv','').replace('.txt','').lower() for filename in os.listdir(path)]})\n",
    "appr_files['appraisal_files'] = appr_files['filename']\n",
    "appr_files=appr_files.set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff15c74c-e020-4bc3-8c86-b75b707a5d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metaphor_files     0\n",
       "appraisal_files    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_df=met_files.join(appr_files, how='outer').reset_index().drop(columns=['filename'])\n",
    "filenames_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b73ff018-4cab-4a74-b9e9-6dd12be85b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(appr_files.appraisal_files.unique())-set(met_files.metaphor_files.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e599947-0754-429c-8e03-0fe535cc2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aboriginal_17'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(met_files.metaphor_files.unique())-set(appr_files.appraisal_files.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00aa346e-406d-4c4c-9f61-ba658f47b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames_df.to_csv('filenames.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a0b9f-8df3-4857-badd-1e43ba0aa333",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da61be64-3d7e-4702-9e3a-e9e116dcfc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hillary_5\n",
      "  indices    text          label\n",
      "7   39-45  damage  pos[2]|neg[3]\n",
      "hillary_45\n",
      "    indices        text          label\n",
      "89  428-438  destroying  pos[6]|neg[7]\n",
      "90  439-445      others  pos[6]|neg[7]\n",
      "91  446-448          to  pos[6]|neg[7]\n",
      "92  449-453        gain  pos[6]|neg[7]\n",
      "93  454-459       power  pos[6]|neg[7]\n",
      "94  460-464        over  pos[6]|neg[7]\n",
      "95  465-471      others  pos[6]|neg[7]\n",
      "hillary_80\n",
      "  indices       text          label\n",
      "8   44-53  illegally  pos[1]|neg[2]\n",
      "budget_18\n",
      "   indices  text          label\n",
      "18   78-82  good  neg[2]|pos[3]\n",
      "budget_22\n",
      "    indices    text          label\n",
      "24  134-136      in  neg[3]|pos[4]\n",
      "25  137-143  charge  neg[3]|pos[4]\n",
      "32  173-178   aware  neg[3]|pos[5]\n",
      "budget_25\n",
      "     indices     text           label\n",
      "39   178-185  awesome   neg[4]|pos[5]\n",
      "102  486-493  surplus  neg[9]|pos[11]\n",
      "107  517-521     good  neg[9]|pos[12]\n",
      "budget_34\n",
      "  indices    text          label\n",
      "8   50-56  fooled  pos[1]|neg[2]\n",
      "daycare_1\n",
      "    indices         text          label\n",
      "30  155-159         just  neg[2]|pos[3]\n",
      "31  160-171  established  neg[2]|pos[3]\n",
      "32  172-173            a  neg[2]|pos[3]\n",
      "33  174-182     national  neg[2]|pos[3]\n",
      "34  183-188        child  neg[2]|pos[3]\n",
      "35  189-193         care  neg[2]|pos[3]\n",
      "36  194-201      program  neg[2]|pos[3]\n",
      "38  203-206          not  neg[2]|pos[4]\n",
      "39  207-215     promised  neg[2]|pos[4]\n",
      "40  215-216            ,  neg[2]|pos[4]\n",
      "41  217-219           or  neg[2]|pos[4]\n",
      "42  220-228     planne4d  neg[2]|pos[4]\n",
      "43  228-229            ,  neg[2]|pos[4]\n",
      "44  230-233          but  neg[2]|pos[4]\n",
      "45  234-245  established  neg[2]|pos[4]\n",
      "daycare_13\n",
      "    indices         text          label\n",
      "37  202-213  interesting  neg[5]|pos[7]\n",
      "china_6\n",
      "  indices   text          label\n",
      "7   42-47  peace  neg[2]|pos[3]\n",
      "pope_17\n",
      "    indices           text          label\n",
      "26  138-151  authoritarian  pos[3]|neg[4]\n",
      "trump_9\n",
      "    indices    text          label\n",
      "40  177-183  enmity  pos[2]|neg[3]\n",
      "aboriginal_2\n",
      "   indices    text          label\n",
      "20   85-91  thrive  neg[1]|pos[2]\n",
      "aboriginal_8\n",
      "   indices       text          label\n",
      "4    21-29   Violence  pos[2]|neg[3]\n",
      "5    30-37    against  pos[2]|neg[3]\n",
      "6    38-43      women  pos[2]|neg[3]\n",
      "7    44-47        and  pos[2]|neg[3]\n",
      "8    48-56   children  pos[2]|neg[3]\n",
      "16  92-101  addiction  pos[4]|neg[5]\n",
      "aboriginal_10\n",
      "       indices   text                    label\n",
      "210   998-1003  awful  pos[16]|pos[17]|neg[18]\n",
      "211  1004-1009  abuse  pos[16]|pos[17]|neg[18]\n",
      "aboriginal_28\n",
      "  indices         text          label\n",
      "7   45-56  residential  pos[1]|neg[2]\n",
      "8   57-64      schools  pos[1]|neg[2]\n",
      "aboriginal_30\n",
      "    indices      text          label\n",
      "5     44-52  muddying  pos[2]|neg[3]\n",
      "6     53-56       the  pos[2]|neg[3]\n",
      "7     57-63    waters  pos[2]|neg[3]\n",
      "10    78-85   poverty  pos[2]|neg[4]\n",
      "11    86-89       and  pos[2]|neg[4]\n",
      "12    90-96    social  pos[2]|neg[4]\n",
      "13   97-105  problems  pos[2]|neg[4]\n",
      "18  124-131   violent  pos[2]|neg[5]\n",
      "19  132-137     crime  pos[2]|neg[5]\n",
      "aboriginal_50\n",
      "    indices      text          label\n",
      "35  163-168     grown  neg[6]|pos[7]\n",
      "36  168-169         ,  neg[6]|pos[7]\n",
      "37  170-178  educated  neg[6]|pos[7]\n",
      "38  179-182       and  neg[6]|pos[7]\n",
      "39  183-191  employed  neg[6]|pos[7]\n",
      "aboriginal_57\n",
      "    indices            text          label\n",
      "44  243-247            pony  neg[6]|pos[7]\n",
      "45  248-251             ing  neg[6]|pos[7]\n",
      "46  252-254              up  neg[6]|pos[7]\n",
      "47  255-258             and  neg[6]|pos[7]\n",
      "48  259-268       accepting  neg[6]|pos[7]\n",
      "49  269-283  responsibility  neg[6]|pos[7]\n",
      "belgium_22\n",
      "  indices        text          label\n",
      "4   29-39  productive  neg[1]|pos[2]\n",
      "belgium_43\n",
      "  indices     text          label\n",
      "4   33-40  honesty  neg[1]|pos[2]\n",
      "belgium_55\n",
      "    indices       text          label\n",
      "25  143-150    suicide  pos[2]|neg[3]\n",
      "31  182-191  martyrdom  pos[2]|neg[4]\n",
      "belgium_62\n",
      "    indices     text          label\n",
      "66  412-419  rescues  neg[6]|pos[7]\n",
      "belgium_75\n",
      "    indices   text          label\n",
      "59  345-350  happy  neg[7]|pos[8]\n",
      "belgium_77\n",
      "    indices       text          label\n",
      "51  245-254  attacking  pos[2]|neg[3]\n",
      "52  254-255          ,  pos[2]|neg[3]\n",
      "53  256-264   shooting  pos[2]|neg[3]\n",
      "54  264-265          ,  pos[2]|neg[3]\n",
      "55  266-273    suicide  pos[2]|neg[3]\n",
      "56  274-281    bombing  pos[2]|neg[3]\n",
      "57  282-285        and  pos[2]|neg[3]\n",
      "58  286-293    killing  pos[2]|neg[3]\n",
      "belgium_91\n",
      "    indices      text          label\n",
      "54  289-295    agency  neg[7]|pos[8]\n",
      "55  296-299       and  neg[7]|pos[8]\n",
      "56  300-308  autonomy  neg[7]|pos[8]\n",
      "belgium_103\n",
      "    indices       text          label\n",
      "14    78-87  terrorism  pos[2]|neg[3]\n",
      "27  161-170  terrorism  pos[4]|neg[5]\n",
      "belgium_112\n",
      "       indices       text            label\n",
      "18      91-100  apartheid    pos[4]|neg[5]\n",
      "243  1199-1206    radical  pos[36]|neg[37]\n",
      "budget_123\n",
      "     indices       text          label\n",
      "110  495-504  democracy  neg[6]|pos[7]\n",
      "hillary_126\n",
      "    indices     text                 label\n",
      "11    52-56     went         neg[1]|pos[2]\n",
      "12    57-61     with         neg[1]|pos[2]\n",
      "13    62-67    Trump         neg[1]|pos[2]\n",
      "14    68-71      and         neg[1]|pos[2]\n",
      "15    72-78   turned         neg[1]|pos[2]\n",
      "16    79-83     down         neg[1]|pos[2]\n",
      "17    84-87      the         neg[1]|pos[2]\n",
      "18    88-94   option         neg[1]|pos[2]\n",
      "19    95-97       to         neg[1]|pos[2]\n",
      "20   98-102     back         neg[1]|pos[2]\n",
      "21  103-110  Billary  neg[1]|pos[2]|neg[3]\n",
      "property_29\n",
      "    indices    text          label\n",
      "19  108-114  abuses  pos[1]|neg[2]\n",
      "property_31\n",
      "   indices  text          label\n",
      "11   56-60  good  neg[1]|pos[2]\n",
      "property_60\n",
      "     indices     text          label\n",
      "115  541-548  imposed  neg[6]|pos[7]\n",
      "116  549-550        a  neg[6]|pos[7]\n",
      "117  551-558  similar  neg[6]|pos[7]\n",
      "118  559-562      tax  neg[6]|pos[7]\n",
      "property_75\n",
      "    indices       text          label\n",
      "27  146-153    totally  neg[1]|pos[4]\n",
      "28  154-163  avoidable  neg[1]|pos[4]\n",
      "property_81\n",
      "  indices     text          label\n",
      "7   48-55  problem  pos[1]|neg[2]\n",
      "property_90\n",
      "  indices    text          label\n",
      "2   14-20  honest  neg[1]|pos[2]\n",
      "property_94\n",
      "    indices     text          label\n",
      "32  185-190    using  pos[2]|neg[3]\n",
      "33  191-194      our  pos[2]|neg[3]\n",
      "34  195-202  economy  pos[2]|neg[3]\n",
      "35  203-205       as  pos[2]|neg[3]\n",
      "36  206-207        a  pos[2]|neg[3]\n",
      "37  208-213    cheap  pos[2]|neg[3]\n",
      "38  214-218     bank  pos[2]|neg[3]\n",
      "refugees_20\n",
      "    indices     text          label\n",
      "15    83-90  helping  neg[2]|pos[3]\n",
      "16    91-92        a  neg[2]|pos[3]\n",
      "17    93-99   fellow  neg[2]|pos[3]\n",
      "18  100-105    human  neg[2]|pos[3]\n",
      "19  106-111    being  neg[2]|pos[3]\n",
      "refugees_54\n",
      "    indices     text          label\n",
      "21   99-103     rich  neg[3]|pos[4]\n",
      "34  147-154  problem  pos[5]|neg[6]\n",
      "refugees_69\n",
      "    indices      text                 label\n",
      "10    64-67       war  pos[1]|pos[2]|neg[3]\n",
      "19  108-115   tsunami         pos[4]|neg[5]\n",
      "20  116-118        of         pos[4]|neg[5]\n",
      "21  119-127  refugees         pos[4]|neg[5]\n",
      "trump_33\n",
      "    indices         text          label\n",
      "3     25-32      extreme  pos[2]|neg[3]\n",
      "20  104-115  constrained  neg[6]|pos[7]\n",
      "trump_57\n",
      "    indices        text          label\n",
      "70  318-322        felt  pos[4]|neg[5]\n",
      "71  323-324           a  pos[4]|neg[5]\n",
      "72  325-333    distinct  pos[4]|neg[5]\n",
      "73  334-344  disconnect  pos[4]|neg[5]\n",
      "trump_71\n",
      "       indices        text                 label\n",
      "53     299-309  meaningful         neg[7]|pos[8]\n",
      "54     309-310           ,         neg[7]|pos[8]\n",
      "55     311-320   sometimes         neg[7]|pos[8]\n",
      "56     321-328     painful  neg[7]|pos[8]|neg[9]\n",
      "57     329-332         but         neg[7]|pos[8]\n",
      "58     333-342   necessary         neg[7]|pos[8]\n",
      "180  1021-1029    economic       neg[21]|pos[22]\n",
      "181  1030-1035       giant       neg[21]|pos[22]\n",
      "trump_76\n",
      "   indices       text          label\n",
      "16  96-105  socialism  pos[2]|neg[3]\n",
      "trump_93\n",
      "  indices       text          label\n",
      "3   24-33  political  pos[1]|neg[2]\n",
      "4   34-42   trifecta  pos[1]|neg[2]\n",
      "trump_114\n",
      "   indices  text          label\n",
      "11   54-58  lies  pos[2]|neg[3]\n",
      "trump_115\n",
      "    indices    text          label\n",
      "93  495-501  afraid  pos[5]|neg[6]\n",
      "trump_126\n",
      "    indices   text          label\n",
      "42  175-180  truth  neg[4]|pos[5]\n",
      "48  199-203   good  neg[4]|pos[6]\n",
      "uber_10\n",
      "  indices       text          label\n",
      "7   35-39       fair  neg[1]|pos[2]\n",
      "8   40-43        and  neg[1]|pos[2]\n",
      "9   44-53  civilized  neg[1]|pos[2]\n",
      "uber_18\n",
      "    indices  text            label\n",
      "78  334-338  fair  neg[10]|pos[11]\n",
      "uber_27\n",
      "    indices  text            label\n",
      "66  273-277  true  neg[10]|pos[11]\n",
      "uber_41\n",
      "   indices  text          label\n",
      "16   60-64  real  neg[1]|pos[2]\n",
      "uber_45\n",
      "    indices  text          label\n",
      "49  280-284  want  neg[8]|pos[9]\n",
      "uber_48\n",
      "    indices    text           label\n",
      "69  342-345     new  neg[9]|pos[11]\n",
      "70  346-349     and  neg[9]|pos[11]\n",
      "71  350-352      in  neg[9]|pos[11]\n",
      "72  353-359  proved  neg[9]|pos[11]\n",
      "73  360-363     way  neg[9]|pos[11]\n",
      "uber_53\n",
      "  indices         text          label\n",
      "2   12-23  competition  neg[1]|pos[2]\n",
      "uber_56\n",
      "    indices      text          label\n",
      "25  108-116  solution  pos[2]|neg[3]\n",
      "uber_62\n",
      "       indices       text            label\n",
      "258  1209-1218  middlemen  pos[17]|neg[18]\n",
      "uber_76\n",
      "    indices       text          label\n",
      "43  241-250  collusion  pos[8]|neg[9]\n",
      "uber_90\n",
      "    indices  text          label\n",
      "44  240-244  just  neg[5]|pos[6]\n",
      "uber_108\n",
      "   indices  text          label\n",
      "15   86-89   not  neg[2]|pos[3]\n",
      "16   90-92    so  neg[2]|pos[3]\n",
      "17   93-97  hard  neg[2]|pos[3]\n",
      "uber_114\n",
      "  indices   text          label\n",
      "6   27-32  worry  pos[2]|neg[3]\n",
      "uber_116\n",
      "    indices  text          label\n",
      "53  234-238  good  neg[8]|pos[9]\n",
      "watch_55\n",
      "     indices      text          label\n",
      "110  466-471     still  pos[5]|neg[6]\n",
      "111  472-480  reaching  pos[5]|neg[6]\n",
      "112  481-484       for  pos[5]|neg[6]\n",
      "113  485-490     their  pos[5]|neg[6]\n",
      "114  491-496     phone  pos[5]|neg[6]\n",
      "Aboriginal_43\n",
      "   indices  text          label\n",
      "11   56-60  real  neg[2]|pos[3]\n",
      "Belgium_100\n",
      "    indices      text          label\n",
      "48  272-280  moderate  neg[4]|pos[5]\n",
      "Belgium_116\n",
      "    indices        text          label\n",
      "27  123-133  terrorists  pos[2]|neg[3]\n",
      "Uber_82\n",
      "    indices   text          label\n",
      "19   96-100   real  neg[2]|pos[3]\n",
      "20  101-106  truth  neg[2]|pos[3]\n",
      "belgium_122\n",
      "  indices  text          label\n",
      "8   47-51  play  neg[2]|pos[3]\n",
      "9   52-56  nice  neg[2]|pos[3]\n",
      "belgium_124\n",
      "  indices    text          label\n",
      "4   25-29    what  pos[1]|neg[2]\n",
      "5   30-33     you  pos[1]|neg[2]\n",
      "6   34-37     say  pos[1]|neg[2]\n",
      "7   38-41     she  pos[1]|neg[2]\n",
      "8   42-44      is  pos[1]|neg[2]\n",
      "9   45-51  saying  pos[1]|neg[2]\n",
      "budget_44\n",
      "   indices     text          label\n",
      "15   64-71  prudent  neg[1]|pos[2]\n",
      "budget_84\n",
      "    indices         text                 label\n",
      "68  335-343     economic  neg[4]|neg[5]|pos[6]\n",
      "69  344-355  stewardship  neg[4]|neg[5]|pos[6]\n",
      "budget_91\n",
      "    indices    text          label\n",
      "26  116-122  honest  pos[1]|neg[2]\n"
     ]
    }
   ],
   "source": [
    "# checking which units contain both a positive and a negative label\n",
    "for name, df in appraisal_dict.items():\n",
    "    cleaned_df = df[df.label != '_'][['indices', 'text', 'label']].dropna()\n",
    "    if len(cleaned_df) > 0:\n",
    "        neg_df = cleaned_df[cleaned_df.label.str.contains('neg')]\n",
    "        pos_neg = neg_df[neg_df.label.str.contains('pos')]\n",
    "        if len(pos_neg) > 0:\n",
    "            print(name)\n",
    "            print(pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55913fc3-ac0a-4297-bfa6-0576acdd74fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
